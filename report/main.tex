\documentclass[a4paper,table]{article}

\usepackage[frenchb]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{a4wide}
\usepackage{enumitem}

\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{steelblue}{rgb}{0.16,0.37,0.58}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{blue}{rgb}{0,0,0.7}
\definecolor{hlColor}{rgb}{0.94,0.94,0.94}
\definecolor{shadecolor}{rgb}{0.96,0.96,0.96}
\definecolor{TFFrameColor}{rgb}{0.96,0.96,0.96}
\definecolor{TFTitleColor}{rgb}{0.00,0.00,0.00}
\definecolor{lightred}{rgb}{1,0.96,0.96}
\definecolor{darkred}{rgb}{0.85,0.33,0.31}
\definecolor{lightblue}{HTML}{EBF5FA}
\definecolor{lightblue2}{HTML}{E3F2FA}
\definecolor{darkblue}{HTML}{D2DCE1}
\definecolor{lightyellow}{HTML}{FFFAE6}
\definecolor{darkyellow}{HTML}{FAE6BE}

\usepackage{listings}
\lstset{
	language=C,
	basicstyle=\scriptsize,
	numbers=left,                   % where to put the line-numbers
  	numberstyle=\tiny\color{gray},
	commentstyle=\color{steelblue},
	stringstyle=\color{darkred},
	backgroundcolor=\color{shadecolor},
    keywordstyle=\color{dkgreen},
	frame=single,                   % adds a frame around the code
 	rulecolor=\color{black},
	emph={},
	emphstyle=\color{mauve},
	morekeywords=[2]{},
	keywordstyle=[2]{\color{dkgreen}},
	showstringspaces=false,
  	tabsize=4,
	moredelim=[is][\small\ttfamily]{/!}{!/},
	breaklines=true
}

\usepackage{hyperref}
\hypersetup{
	colorlinks=true, % false: boxed links; true: colored links
	linkcolor=black, % color of internal links
	urlcolor=blue,   % color of external links
	citecolor=blue
}
\newcommand{\hhref}[1]{\href{#1}{#1}}

\usepackage{makecell}

\usepackage{eurosym} %\euro -> €

\usepackage{soul}
\sethlcolor{hlColor}

\title{INF5101A - TP2 MPI}

\date{\today}

\begin{document}
\maketitle
\newpage

\section{Calcul de $\pi$}

Dans cet exercice, l'objectif est de calculer une valeur la plus proche de
$\pi$. Cette valeur peut s'obtenir avec un calcul d'intégrale. Par conséquent,
pour atteindre la plus grande précision, il faudra effectuer les calculs avec
des très petits pas entre les bornes de l'intervalle. En procédant de cette
façon, le calcul de la valeur de $\pi$ demandera beaucoup de temps. A l'aide de
la bibliothèque MPI, nous pouvons paralléliser ces calculs sur un nombre de
processeurs que nous choisissons. \\

Pour implémenter cette théorie, nous avons fait en sorte que chaque processeur
qui exécute le programme se détermine des bornes d'intervalle en fonction de
leur numéro de tâche. Lorsque tous les calculs sont terminés, nous utilisons la
fonction \hl{MPI\_Reduce()} qui est ici configurée pour calculer sur le
processeur 0 la somme de toutes les valeurs obtenues par chaque processeur.

\section{Structure de données en parallèle}

Dans l'exécution d'algorithme avec des matrices, nous avons tendance à diviser
les données entre les processeurs qui participent à la parallélisation.
Cependant, il arrive que ceux-ci aient besoin de données voisines stockées sur
les autres processeurs. C'est pourquoi nous faisons du recouvrement de données.

Dans cet exercice, nous faisons une décomposition 1D d'une matrice sur plusieurs
processus. Une fois que cela est fait, deux lignes sont ajoutées autour
de cette matrice et représentent la dernière ligne du processeur de numéro
précédent dans le classement des tâches et la première ligne du processeur de
numéro suivant. C'est le recouvrement de données. \\

\begin{lstlisting}
typedef struct LocalMatrix {
    double* beforeLine;
    double** matrix;
    double* afterLine;

    int innerLines;
    int totalLines;
    int cols;
} LocalMatrix;
\end{lstlisting}
\

Pour mettre à jour les lignes de recouvrement, le programme utilise
\hl{MPI\_Send()} pour envoyer un buffer de données avec un type choisi
(e.g. \hl{MPI\_DOUBLE}) à un destinataire, puis \hl{MPI\_Recv()} pour recevoir
les données qui lui sont destinées. \\

Après un ensemble d'actions parallèles avec ces fonctions, nous pouvons nous
assurer à ce que les programmes lancés parallèlement se rejoignent en un même
point dans le déroulement du programme avec la fonction \hl{MPI\_Barrier()}.
Elle fait attendre les différentes tâches jusqu'à ce que toutes les tâches
arrivent à cette barrière.

\end{document}
